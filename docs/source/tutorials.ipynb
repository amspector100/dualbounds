{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a6fbe2-9838-433c-b256-b2ab235568bd",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\opt}{^{\\star}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64317efe-6f20-4dca-9c1c-6f14e2fc872e",
   "metadata": {},
   "source": [
    "# Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f983c4b2-8531-4e05-ba3d-f4ea2add9dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys; sys.path.insert(0, \"../../\")\n",
    "import numpy as np\n",
    "import dualbounds as db\n",
    "from dualbounds.generic import DualBounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a189812-274d-4e21-ac4a-e1cb4e1a0fd3",
   "metadata": {},
   "source": [
    "## Minimalist review of dual bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e918257-8594-48d5-ab78-7128c5524e2a",
   "metadata": {},
   "source": [
    "In this section, we give a minimal review the dual bounds framework; a more complete review can be found in the first four pages of [Ji et al. (2023)](https://arxiv.org/abs/2310.08115). Users familiar with this content should skip this section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2d9a0-8256-4bbb-9188-7219ae5cae52",
   "metadata": {},
   "source": [
    "Given i.i.d. outcomes $Y_i \\in \\mathcal{Y}$, treatments $W_i \\in \\{0,1\\}$ and pre-treatment covariates $X_i \\in \\mathcal{Y}$, dual bounds allow analysts to use machine learning to perform inference on partially identified estimands of the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b35c0c-0917-4852-a65c-e421163c96b5",
   "metadata": {},
   "source": [
    "$$\\theta = E[f(Y_i(0), Y_i(1), X_i)], $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2b33b-dfd3-46d1-a8a3-f47cf48698ea",
   "metadata": {},
   "source": [
    "where $Y_i(1), Y_i(0) \\in \\mathcal{Y}$ denote potential outcomes. Such estimands are *partially identified* because we never observe the joint law of the potential outcomes, but the data still contains information on the law of $(Y(0), X)$ and $(Y(1), X)$ allowing us to *bound* $\\theta$. (More generally, dual bounds can provde bounds on the solutions to generic optimization problems, but we defer discussion of this until later in the tutorial for simplicity).\n",
    "\n",
    "Thus, to bound $\\theta$, one usually must estimate the laws of $(Y(1), X)$ and $(Y(0), X)$, typically using sophisticated machine learning techniques. However, it is not clear if the resulting bounds on $\\theta$ will be valid if the learned machine learning models are misspecified or inaccurate. For example, if one models $Y$ as having a linear relationship with $(X,W)$, but in truth $Y$ has a highly nonlinear relationship with $(X,W$), naive approaches could lead to inaccurate inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148683bc-e2af-49f4-8fca-69262b83e95c",
   "metadata": {},
   "source": [
    "The Dual Bounds methodology is designed to leverage the benefits of sophisticated ML models without sacrificing validity. It has three key properties:\n",
    "1. Dual bounds can wrap on top of any ML model (e.g. generalized linear models, random forests, neural networks, etc).\n",
    "2. In randomized experiments, dual bounds yield provably valid confidence intervals on $\\theta$, even if the underlying ML model is arbitrarily misspecified or inaccurate. In observational studies, they have remarkably strong double robustness properties (see Section 3.4 of [Ji et al. (2023)](https://arxiv.org/abs/2310.08115)).\n",
    "3. On the other hand, if the underlying ML model is highly accurate, dual bounds yield extremely sharp confidence bounds in a formal sense (see Section 3.2 of [Ji et al. (2023)](https://arxiv.org/abs/2310.08115))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39579b0b-f332-48db-8400-c2e25163ea35",
   "metadata": {},
   "source": [
    "We refer the reader to the original paper for more details on how dual bounds work. In the next section, we show how to use dual bounds to perform inference on a variety of estimands "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b271090-0a44-41c9-87b6-868eccf242e8",
   "metadata": {},
   "source": [
    "## The ``DualBounds`` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139df393-4437-4d89-bbf9-250725a27cf6",
   "metadata": {},
   "source": [
    "The ``DualBounds`` class is the main class in the package. The main usage is as follows. \n",
    "\n",
    "**Step 1**: one should initialize the ``DualBounds`` class, which takes as an input (i) the data, (ii) the definition of the function $f$ (which defines the estimand $\\theta$), and (iii) a description of the outcome model to use as an input. The user can also input a vector of propensity scores if they are known; else they will be estimated from the data. \n",
    "\n",
    "For example, below, we show how to compute $E[\\mathbb{I}(Y(1) > Y(0)]$, the probability that the treatment effect is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f168fe92-747c-4ed9-b965-2579394c6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data from a heavy-tailed linear model\n",
    "data = db.gen_data.gen_regression_data(\n",
    "    n=900, # Num. datapoints\n",
    "    p=30, # Num. covariates\n",
    "    r2=0.95, # population R^2\n",
    "    tau=3, # average treatment effect\n",
    "    interactions=True, # ensures treatment effect is heterogenous\n",
    "    eps_dist='laplace', # heavy-tailed residuals\n",
    "    sample_seed=123, # random seed\n",
    ")\n",
    "\n",
    "# Initialize dual bounds object\n",
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: y0 < y1, # defines the estimand\n",
    "    X=data['X'], # n x p covariate matrix\n",
    "    W=data['W'], # n-length treatment vector\n",
    "    y=data['y'], # n-length outcome vector\n",
    "    pis=data['pis'], # n-length propensity scores (optional)\n",
    "    Y_model='ridge', # description of model for Y | X, W\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286a85b-9358-48c5-845a-9caf040b17dd",
   "metadata": {},
   "source": [
    "**Step 2**: after initialization, the ``compute_dual_bounds`` method fits the underlying outcome model and produces the final estimates and confidence bounds for the sharp partial identification bounds $\\theta_L \\le \\theta \\le \\theta_U$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a01e35-e141-419e-9370-db8ce1669fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 828.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([0.57745911, 0.92498299]),\n",
       " 'ses': array([0.02331765, 0.0129798 ]),\n",
       " 'cis': array([0.53175736, 0.95042292])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute dual bounds and observe output\n",
    "dbnd.compute_dual_bounds(\n",
    "    nfolds=5, # number of cross-fitting folds\n",
    "    alpha=0.05 # nominal level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cc518-c07b-4122-8a14-2ed6d0865cff",
   "metadata": {},
   "source": [
    "Note that there are two estimates---a lower and an upper estimate---because $\\theta$ is not identified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c6d52-7ecf-4d50-89bd-2874d14f877e",
   "metadata": {},
   "source": [
    "Another example below bounds a different estimand, the positive treatment effect $E[\\max(Y(1) - Y(0), 0)]$, using a different underlying ML model (a k-nearest neighbors regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb392834-7cd5-4795-9ebf-85c10d58ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 579.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([2.52594772, 4.27917408]),\n",
       " 'ses': array([0.18387067, 0.15829605]),\n",
       " 'cis': array([2.22350738, 4.5395479 ])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # new estimand\n",
    "    X=data['X'], # n x p covariate matrix\n",
    "    W=data['W'], # n-length treatment vector\n",
    "    y=data['y'], # n-length outcome vector\n",
    "    pis=data['pis'], # n-length propensity scores (optional)\n",
    "    Y_model='knn', # description of model for Y | X, W\n",
    ")\n",
    "dbnd.compute_dual_bounds(\n",
    "    alpha=0.1 # nominal level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76844c5-f16e-4fac-a9ac-a8b3950da2a0",
   "metadata": {},
   "source": [
    "## Choosing the outcome model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4c951-6807-4fce-b384-30c0fb477525",
   "metadata": {},
   "source": [
    "Dual bounds wrap on top of an underlying model which estimates the conditional distributions of $Y(1) \\mid X$ and $Y(0) \\mid X$. To allow for maximum flexibility, ``dualbounds`` gives the user four ways to specify the underlying model, listed below in order of increasing flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145bf46-7ed7-4cd2-b64b-760f9121e114",
   "metadata": {},
   "source": [
    "### Method 1: String identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e58aaa-34c0-4039-8760-8122a81036cb",
   "metadata": {},
   "source": [
    "The easiest way to choose the model is to use one of the string identifiers, such as ``'ridge', 'lasso', 'elasticnet', 'randomforest', 'knn'`` (see the API reference for a complete list), as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83597e1e-9dc9-41d3-97ac-a93c92bc5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnd = DualBounds(\n",
    "    Y_model='randomforest', # use random forest model\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # estimand\n",
    "    X=data['X'], W=data['W'], y=data['y'], # data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482e72-00fa-4a31-9273-3b16185ecf6c",
   "metadata": {},
   "source": [
    "For binary data, these string identifiers assume a nonparametric model where $Y_i \\sim \\text{Bern}(\\mu(X_i, W_i))$ and the conditional mean function $\\mu$ is estimated via one of the models listed above (e.g., a random forest classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39d70e-5290-4be9-916b-50cbede13ba1",
   "metadata": {},
   "source": [
    "For nonbinary data, these string identifiers use a semiparametric regression model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092990ab-ca46-49af-8870-de878e2b2758",
   "metadata": {},
   "source": [
    "$$Y_i = \\mu(X_i, W_i) + \\epsilon_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323922f0-cadc-4cc8-ba1f-ccffba1b3294",
   "metadata": {},
   "source": [
    "where the conditional mean function $\\mu(\\cdot, \\cdot)$ is approximated using one of the models listed above (e.g., a random forest or k-nearest neighbors regressor). All methods automatically create interaction terms between the covariates and the treatment.\n",
    " \n",
    "\n",
    "By default, these string identifiers assume Gaussian homoskedastic residuals, i.e., $\\epsilon_i \\stackrel{\\mathrm{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma^2)$. This lightweight approach may not be realistic, but nonetheless we have found that it yields reasonably tight confidence intervals even under misspecification. Of course, it provably yields valid confidence intervals even under arbitrary misspecification of the outcome model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f898a-a6f1-404c-b0de-4820bbda0dd9",
   "metadata": {},
   "source": [
    "### Method 2: Input a class inheriting from ``dist_reg.DistReg``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1435d-cf8a-4c11-a12b-bf28f1eae938",
   "metadata": {},
   "source": [
    "By default, the string identifiers assume Gaussianity and homoskedasticity. Analysts can change these assumptions by initializing either a ``CtsDistReg`` or ``BinaryDistReg`` class and passing it into the ``dualbounds`` class instantiation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529ddd6-d094-4e1a-9edd-372dd0a72c0e",
   "metadata": {},
   "source": [
    "For example, below we initialize a class which assumes heavy-tailed Laplace errors and heteroskedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6c50ae-2806-4df4-8138-b1fd93e4a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 611.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([2.75821933, 3.3190261 ]),\n",
       " 'ses': array([0.23200022, 0.16681487]),\n",
       " 'cis': array([2.30350725, 3.64597724])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_model = db.dist_reg.CtsDistReg(\n",
    "    model_type='elasticnet', \n",
    "    eps_dist='laplace',\n",
    "    how_transform='interactions', # create interactions btwn X and W\n",
    "    heterosked=True,\n",
    ")\n",
    "dbnd = DualBounds(\n",
    "    Y_model=Y_model, # use random forest model\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # estimand\n",
    "    X=data['X'], W=data['W'], y=data['y'], pis=data['pis'], # data\n",
    ")\n",
    "dbnd.compute_dual_bounds(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da62a40-daad-4d38-a912-f6331dfac790",
   "metadata": {},
   "source": [
    "One can also directly input ``sklearn`` classes. For example, below we show how to use the ``AdaBoostClassifier`` from sklearn for binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d263885-febd-445a-84d2-b0ab98def55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 900/900 [00:00<00:00, 2645.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([0.24130477, 0.37151485]),\n",
       " 'ses': array([0.02993697, 0.02251905]),\n",
       " 'cis': array([0.18262938, 0.41565138])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble as ensemble\n",
    "Y_model = db.dist_reg.BinaryDistReg(\n",
    "    model_type=ensemble.AdaBoostClassifier,\n",
    ")\n",
    "dbnd = DualBounds(\n",
    "    Y_model=Y_model, # use random forest model\n",
    "    f=lambda y0, y1, x: y0 < y1, # estimand\n",
    "    y=data['y'] > 0, # make the outcome binary\n",
    "    X=data['X'], W=data['W'], pis=data['pis'], # data\n",
    ")\n",
    "dbnd.compute_dual_bounds(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc525c-8e8a-44e7-89b5-eae4d3da4810",
   "metadata": {},
   "source": [
    "Analysts can also create custom classes inheritting from ``dualbounds.dist_reg.DistReg``, allowing analysts to use (e.g.) custom conditional variance estimators---see the API reference for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a85ff-860c-4fab-9804-a746dd11070e",
   "metadata": {},
   "source": [
    "### Method 3: Directly input estimated conditional distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a44187-ad1a-48f2-b1a9-78218c5d2eb8",
   "metadata": {},
   "source": [
    "For maximum flexibility, one can also directly input predicted conditional distributions of $Y(1) \\mid X$ and $Y(0) \\mid X$, in the form of a list of batched scipy distributions whose shapes sum to the number of datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf854b53-67f1-4a9a-bb09-33969b4b9196",
   "metadata": {},
   "source": [
    "This is illustrated below, although for simplicity the inputs have nothing to do with the true distributions of $Y(1) \\mid X$ and $Y(0) \\mid X$. Note that in real applications, it is extremely important that the estimates of $Y(1) \\mid X$ and $Y(0) \\mid X$ must be computed using cross-fitting, otherwise the dual bounds may not be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3243ace7-4952-4b31-b4e0-4acd71d1ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 733.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([0.29014241, 1.22454801]),\n",
       " 'ses': array([0.03908947, 0.02725067]),\n",
       " 'cis': array([0.21352846, 1.27795834])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "n = len(data['y']) # number of data-points\n",
    "\n",
    "# Initialize object\n",
    "dbnd = DualBounds(\n",
    "    Y_model='lasso', # this will be ignored\n",
    "    f=lambda y0, y1, x : y0 < y1, # estimand\n",
    "    y=data['y'], X=data['X'], W=data['W'], pis=data['pis'], # data\n",
    ")\n",
    "\n",
    "# Either of the following input formats work\n",
    "y0_dists = stats.norm(loc=np.zeros(n))\n",
    "y1_dists = [\n",
    "    stats.norm(loc=np.zeros(int(n/2)), scale=2), \n",
    "    stats.norm(loc=np.zeros(int(n/2)), scale=3)\n",
    "]\n",
    "# Compute dual bounds using y0_dists and y1_dists\n",
    "dbnd.compute_dual_bounds(\n",
    "    y0_dists=y0_dists,\n",
    "    y1_dists=y1_dists,\n",
    "    suppress_warning=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3262d-b6c9-42b7-b6c0-13da8b1912b7",
   "metadata": {},
   "source": [
    "This syntax can be useful if in simulations one wants to compute an \"oracle dual bound\" which has perfect knowledge of the conditional distributions of $Y(0) \\mid X$ and $Y(1) \\mid X$, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae34c28-476e-4d0e-95ef-133b1cc60ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 481.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([0.58061888, 0.92968078]),\n",
       " 'ses': array([0.02343839, 0.01286777]),\n",
       " 'cis': array([0.53468048, 0.95490115])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute oracle dual bounds using the true conditional dists of Y0/Y1\n",
    "dbnd.compute_dual_bounds(\n",
    "    y0_dists=data['y0_dists'],\n",
    "    y1_dists=data['y1_dists'],\n",
    "    suppress_warning=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370dde1-2801-4f8f-b1a0-c9c3b8720534",
   "metadata": {},
   "source": [
    "Note that the output of the oracle dual bounds is extremely similar to the output of the initial dual bounds in the third cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f763a72-8a66-4cce-ac1f-1939bf9d2e05",
   "metadata": {},
   "source": [
    "### Choosing the propensity score model for observational data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408b84c-b8fc-4e51-bf0d-3a33cbe21d85",
   "metadata": {},
   "source": [
    "Dual bounds can also apply to observational data where the propensity scores must be estimated. In this case, analysts can specify the model used to estimate the propensity scores---the ``W_model``---with one of three methods. First, one can use a string identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca956b23-4a69-4ff4-95dc-19e34d62012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 568.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([0.58088302, 0.93676891]),\n",
       " 'ses': array([0.023641 , 0.0133706]),\n",
       " 'cis': array([0.53454751, 0.96297481])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbnd = DualBounds(\n",
    "    W_model='ridge', # logistic ridge for prop. scores\n",
    "    Y_model='lasso',\n",
    "    f=lambda y0, y1, x: y0 < y1, # estimand\n",
    "    X=data['X'], W=data['W'], y=data['y'], # data\n",
    ")\n",
    "dbnd.compute_dual_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ec004-4f93-4f64-899e-90ca1e08ca42",
   "metadata": {},
   "source": [
    "Second, one can directly input an sklearn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b34e63ca-8785-460a-8ec2-f1b7123298a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:01<00:00, 614.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([0.5770192 , 0.92539417]),\n",
       " 'ses': array([0.02351094, 0.01315318]),\n",
       " 'cis': array([0.5309386 , 0.95117393])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbnd = DualBounds(\n",
    "    W_model=ensemble.AdaBoostClassifier(), \n",
    "    f=lambda y0, y1, x: y0 < y1, # estimand\n",
    "    X=data['X'], W=data['W'], y=data['y'], # data\n",
    ")\n",
    "dbnd.compute_dual_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cdbb00-40b2-4f62-9df4-23bcceb70169",
   "metadata": {},
   "source": [
    "Lastly, analysts can also directly estimate the vector propensity scores and input them, although analysts should ensure that they are correctly employing cross-fitting in this case to ensure validity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0b296-ea71-419a-9e30-22fc58436d41",
   "metadata": {},
   "source": [
    "## Additional estimands and extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf32591-9c92-49be-9c7c-0c5eaf42f1cd",
   "metadata": {},
   "source": [
    "Dual bounds can apply beyond the settings described in the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df63cd-0995-4597-abc0-bffc36fab31d",
   "metadata": {},
   "source": [
    "### Variance of the CATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dade1f9-529f-4eb5-9611-abd16e9dc470",
   "metadata": {},
   "source": [
    "Dual bounds can also be used to *lower-bound* the variance of the conditional average treatment effect $\\theta = \\text{Var}(E[Y(1) - Y(0) \\mid X])$, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd122531-a280-4d0c-9eb6-d8a1ec963661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimate': 7.271835000465313,\n",
       " 'se': 0.5761754092436733,\n",
       " 'lower_ci': 6.324110788810609}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdb = db.varcate.VarCATEDualBounds(\n",
    "    X=data['X'], \n",
    "    W=data['W'], \n",
    "    y=data['y'], \n",
    "    pis=data['pis'],\n",
    "    Y_model='elasticnet',\n",
    ")\n",
    "vdb.compute_dual_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a5cb7-e805-4554-adf8-d62a1486ed9c",
   "metadata": {},
   "source": [
    "### Variance of the ITE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed6ebf4-75cd-4f36-8097-0ccc321d4abf",
   "metadata": {},
   "source": [
    "Dual bounds can also be used to upper and lower bound the variance of the individual treatment effect $\\theta = \\text{Var}(Y(1) - Y(0))$, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9372eca-9280-478b-b9c6-f5992cc0b232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 900/900 [00:02<00:00, 338.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimates': array([ 7.18208094, 16.10882366]),\n",
       " 'ses': array([0.56993296, 0.86895712]),\n",
       " 'cis': array([ 6.06503287, 17.81194832])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdb = db.varite.VarITEDualBounds(\n",
    "    X=data['X'], \n",
    "    W=data['W'], \n",
    "    y=data['y'], \n",
    "    pis=data['pis'],\n",
    "    Y_model='elasticnet',\n",
    ")\n",
    "vdb.compute_dual_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadce15d-3484-46d2-980f-ce9afa381445",
   "metadata": {},
   "source": [
    "### Lee Bounds under monotonicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf0c25-664b-49f1-b61a-5c6654904dee",
   "metadata": {},
   "source": [
    "Lee bounds are a method to bound the average treatment effect in the face of post-treatment nonrandom sample selection, named in honor of  [Lee (2009)](https://www.jstor.org/stable/40247633). Precisely, we assume we observe the following data:\n",
    "- Pre-treatment covariates $X_i \\in \\mathcal{X}$\n",
    "- A binary treatment $W_i \\in \\{0,1\\}$\n",
    "- A post-treatment selection indicator $S_i \\in \\{0,1\\}$.\n",
    "- An outcome $Y_i \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce6a98-26f7-4adf-84a4-bdf7b5c5c254",
   "metadata": {},
   "source": [
    "Note that both $Y_i$ and $S_i$ have potential outcomes $(Y_i(0), Y_i(1))$ and $(S_i(0), S_i(1))$ since both potentially depend on the treatment.\n",
    "\n",
    "A classic example is a setting where $W_i$ denotes enrollment in a job training program, $S_i$ denotes whether a subject entered the labor market, and the outcome $Y_i$ are log-wages. A natural estimand in these settings is the average treatment effect for subjects who would have entered the labor market no matter their treatment status; e.g., "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165992c-a024-4eb7-b255-8442f5046c30",
   "metadata": {},
   "source": [
    "$$E[Y(1) - Y(0) \\mid S(1) = S(0) = 1]. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e5b51-27da-4e55-938b-fcaa76debb94",
   "metadata": {},
   "source": [
    "Dual bounds can be used to bound this partially identified estimand under the **monotonicity** assumption that $S(1) \\ge S(0)$ a.s., as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbcb8ec0-c90c-4ff1-bb32-5a34f10a86fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimates': array([2.08484643, 3.25616402]),\n",
       " 'ses': array([0.2094036 , 0.19805625]),\n",
       " 'cis': array([1.67442291, 3.64434714])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data\n",
    "lee_data = db.gen_data.gen_lee_bound_data(\n",
    "    n=900, # Num. datapoints\n",
    "    p=30, # Num. covariates\n",
    "    r2=0.95, # population R^2\n",
    "    tau=3, # average treatment effect\n",
    "    sample_seed=123,\n",
    ")\n",
    "# fit lee bounds\n",
    "ldb = db.lee.LeeDualBounds(\n",
    "    # data\n",
    "    S=lee_data['S'], \n",
    "    X=lee_data['X'], \n",
    "    W=lee_data['W'],\n",
    "    pis=lee_data['pis'], \n",
    "    y=lee_data['y'],\n",
    "    # Model specifications\n",
    "    Y_model='ridge',\n",
    "    S_model='monotone_logistic',\n",
    ")\n",
    "ldb.compute_dual_bounds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88378eef-dc0f-47d8-97fb-94b7a67987ed",
   "metadata": {},
   "source": [
    "It is also possible to bound this estimand without the monotonicity assumption using the generic ``DualBounds`` class, although we caution that without any other assumptions the bounds might be too wide to be useful. Please see [Ji et al. (2023)](https://arxiv.org/pdf/2310.08115.pdf), Section 2.5 for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
