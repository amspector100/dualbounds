{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a189812-274d-4e21-ac4a-e1cb4e1a0fd3",
   "metadata": {},
   "source": [
    "# Support restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6d943-379c-453f-bf1d-3e8c78bde423",
   "metadata": {},
   "source": [
    "## Main idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631f4d26-a03e-4949-9383-638dd59811b3",
   "metadata": {},
   "source": [
    "``dualbounds`` also allows analysts to restrict the support of $Y(1), Y(0), X$ to yield sharper partial identification bounds. That said, restricting the support of $Y(1), Y(0), X$ is a real assumption---if the assumption is false, the final bounds will *not* be valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5ac27-1036-4203-99ac-d87ad1ad0ac4",
   "metadata": {},
   "source": [
    "In particular, the user can provide a boolean-valued function $s(Y(1), Y(0), X) \\in \\{0,1\\}$, where the support of $Y(1), Y(0), X$ is assumed to be $\\{y_1, y_0, x : s(y_1, y_0, x) = 1\\}$, i.e., the set of values such that $s$ evaluates to True. Below, we give some examples of support restrictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e88870-1291-4f01-a9bf-f6d8f77d8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No support restriction: this does not make any assumptions\n",
    "s1 = lambda y0, y1, x: True\n",
    "# Assume y0 <= y1 holds a.s. \n",
    "s2 = lambda y0, y1, x: y0 <= y1\n",
    "# Assume y0 <= y1 whenever x[0] >= 0\n",
    "s3 = lambda y0, y1, x: (y0 <= y1) | (x[0] < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f15711-0477-4842-83c9-c1b15185c167",
   "metadata": {},
   "source": [
    "Passing this function to a ``DualBounds`` or ``DeltaDualBounds`` object using the ``support_restriction`` argument will yield bounds that incorporate this structural assumption. For example, below, we show how to bound the variance $\\text{Var}(Y(1) - Y(0))$ under the assumption that $Y(0) \\le Y(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e17bc3-2ddc-4224-a47c-9e7dc6f49b6a",
   "metadata": {},
   "source": [
    "**Note**: the correct argument to use is the ``support_restriction`` argument, **not** the ``support`` argument (which is used to specify the marginal support of $Y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1697ce-aca1-4721-8fdf-f52cc3e3cb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62c8af0d113455fb27eac131ad9989b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bae3df6a811413484c0e32fed9754ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import sys; sys.path.insert(0, \"../../../\")\n",
    "import dualbounds as db\n",
    "from dualbounds.varite import VarITEDualBounds\n",
    "\n",
    "# Generate synthetic data from a linear model\n",
    "data = db.gen_data.gen_regression_data(\n",
    "    n=500, p=30, interactions=False, tau=1, sample_seed=123\n",
    ")\n",
    "\n",
    "# Common arguments\n",
    "db_args = dict(\n",
    "    outcome=data['y'],\n",
    "    treatment=data['W'],\n",
    "    covariates=data['X'], \n",
    "    propensities=data['pis'],\n",
    "    how_transform='identity',\n",
    "    eps_dist='gaussian',\n",
    ")\n",
    "# Fit assumption-free dual bounds\n",
    "vdb = VarITEDualBounds(**db_args).fit(verbose=False)\n",
    "# Fit dual bounds assuming Y(0) <= Y(1)\n",
    "vdb_monotone = VarITEDualBounds(\n",
    "    **db_args, \n",
    "    support_restriction=lambda y0, y1, x: y0 <= y1\n",
    ").fit(verbose=True, ninterp=0, grid_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615f245f-8886-452f-b3d8-e50866bffda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assumption-free results are:\n",
      "|            |     Lower |   Upper |\n",
      "|:-----------|----------:|--------:|\n",
      "| Estimate   | 0         | 4.29261 |\n",
      "| SE         | 0.0179071 | 0.26683 |\n",
      "| Conf. Int. | 0         | 4.81558 |\n",
      "The results assuming monotonicity are:\n",
      "|            |      Lower |    Upper |\n",
      "|:-----------|-----------:|---------:|\n",
      "| Estimate   | 0          | 2.5705   |\n",
      "| SE         | 0.00829492 | 0.205357 |\n",
      "| Conf. Int. | 0          | 2.97299  |\n"
     ]
    }
   ],
   "source": [
    "print(\"The assumption-free results are:\")\n",
    "print(vdb.results().to_markdown())\n",
    "print(\"The results assuming monotonicity are:\")\n",
    "print(vdb_monotone.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70799de8-d98a-4599-8ce9-9bd3899493d9",
   "metadata": {},
   "source": [
    "## Best practices and common problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354733d-4f0d-4cbf-862f-8cb4db733ca3",
   "metadata": {},
   "source": [
    "### Ensuring the outcome model is compatible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b357d9-51be-49a5-af2f-9afad0cf58d4",
   "metadata": {},
   "source": [
    "It is important that the estimated outcome model is compatible with any assumed support restriction. For example, consider the following scenario:\n",
    "\n",
    "- You would like to compute bounds which incorporate the monotonicity assumption $Y(0) \\le Y(1)$\n",
    "  \n",
    "- Your outcome model predicts that the conditional average treatment effect $E[Y(1) - Y(0) \\mid X]$ is negative for certain $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eeb66a-9432-4bc0-a79d-8c0064c9c6e5",
   "metadata": {},
   "source": [
    "Here, the estimated outcome model is incompatible with the monotonicity assumption. Note that this can happen even when the monotonicity assumption $Y(0) \\le Y(1)$ is accurate, e.g., because the outcome model has overfit. Mathematically, this will yield completely vacuous bounds (i.e. a bound from $-\\infty$ to $\\infty$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f597d3-0f86-4aaa-931e-9811086f1f04",
   "metadata": {},
   "source": [
    "Incompatible outcome models will not cause errors---instead, ``dualbounds`` will automatically try to force the incompatible outcome model to become compatible with the support restriction. However, this has two consequences:\n",
    "\n",
    "- Computation speed: Forcing the outcome model to be compatible with the support restriction can be slow.\n",
    "- Numerical instability: This procedure can also be numerically unstable, leading to large standard errors and loose bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a6e5f-294b-4536-a2ce-f4a214ed1e1b",
   "metadata": {},
   "source": [
    "Thus, although it is not strictly necessary, the best solution is to ensure the outcome model is compatible with the support restriction. \n",
    "\n",
    "- For example, the sklearn HistGradientBoostingRegressor has an argument (``monotonic_cst``) which can be used to guarantee that $E[Y(1) - Y(0) \\mid X] > 0$.\n",
    "\n",
    "- For bespoke support restrictions, we suggest that analysts implement custom outcome models wrapping the ``dist_reg.DistReg`` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39292d3-4d55-472f-96e0-acb14823202f",
   "metadata": {},
   "source": [
    "**Very important note**: If you think your outcome model should be compatible but you are still getting numerical errors, try setting ``ninterp=0`` and ``grid_size=0`` when calling the ``DualBounds.fit()`` method. These technical arguments (described in the documentation to ``DualBounds.compute_dual_variables()``) are used to ensure validity even when the data are very heavy tailed---however, they can sometimes cause a compatible outcome model to become incompatible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e33920-2237-49f5-858c-880588dc6d00",
   "metadata": {},
   "source": [
    "### Large standard errors and numerical problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186ff17-86af-4d7e-9741-577291f7b081",
   "metadata": {},
   "source": [
    "If you cannot create a compatible outcome model, you may (or may not) have numerical problems and large standard errors. However, ``dualbounds`` has a few ways to address this problem:\n",
    "\n",
    "1. Try setting ``ninterp=0`` and ``grid_size=0`` when calling the ``.fit()`` method.\n",
    "2. Try increasing the value of ``nvals0`` and ``nvals1`` when calling the ``.fit()`` method.\n",
    "3. Try changing the ``interp_fn`` input when calling ``.fit()``.\n",
    "4. Try setting ``dual_strategy='se'`` when calling the ``.fit()`` method.\n",
    "5. If the outcome variable is heavy-tailed, try transforming it to make it lighter tailed, e.g., by using a ``np.arcsinh`` transformation. This won't necessarily change the estimand since one can just undo this transformation when specifying the estimand in the ``DualBounds`` class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2b85f-991f-4255-a270-89912b56992f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9dd067-1fa7-40a2-a137-67ea285a34ea",
   "metadata": {},
   "source": [
    "In sum, incorporating support restrictions can substantially sharpen partial identification bounds. However, for optimal statistical and computational performance, we recommend the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee781da-ab15-4a6d-8f8d-6bada067a517",
   "metadata": {},
   "source": [
    "1. Try to ensure that the outcome model is compatible with the support restriction.\n",
    "2. Always inspect the diagnostic results (via the ``.diagnostics()`` method) to see if there are major numerical problems. If so, see the section on \"large standard errors and numerical problems.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
