{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a0b296-ea71-419a-9e30-22fc58436d41",
   "metadata": {},
   "source": [
    "# Additional estimands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf32591-9c92-49be-9c7c-0c5eaf42f1cd",
   "metadata": {},
   "source": [
    "Dual bounds can apply beyond the settings described in the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df63cd-0995-4597-abc0-bffc36fab31d",
   "metadata": {},
   "source": [
    "## Variance of the CATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dade1f9-529f-4eb5-9611-abd16e9dc470",
   "metadata": {},
   "source": [
    "Dual bounds can also be used to *lower-bound* the variance of the conditional average treatment effect $\\theta = \\text{Var}(E[Y(1) - Y(0) \\mid X])$, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae24daaf-2e4f-4b36-80af-c0e08e1ce605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys; sys.path.insert(0, \"../../../\")\n",
    "import numpy as np\n",
    "import dualbounds as db\n",
    "from dualbounds.generic import DualBounds\n",
    "# Generate synthetic data\n",
    "data = db.gen_data.gen_regression_data(n=500, p=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd122531-a280-4d0c-9eb6-d8a1ec963661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06725500de6d48c2ae7a45e956e55a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting cluster bootstrap to aggregate results.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5766755269f14a8c9c18467a19499616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |    Lower |   Upper |\n",
      "|:-----------|---------:|--------:|\n",
      "| Estimate   | 8.48493  |     nan |\n",
      "| SE         | 0.748497 |     nan |\n",
      "| Conf. Int. | 6.98069  |     nan |\n"
     ]
    }
   ],
   "source": [
    "vdb = db.varcate.CalibratedVarCATEDualBounds(\n",
    "    outcome=data['y'],\n",
    "    treatment=data['W'], \n",
    "    covariates=data['X'],\n",
    "    propensities=data['pis'],\n",
    "    outcome_model='elasticnet',\n",
    ")\n",
    "vdb.fit()\n",
    "print(vdb.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4fb729-bfda-41da-93a4-f1761c9f7c26",
   "metadata": {},
   "source": [
    "We broadly recommend using the class ``CalibratedVarCATEDualBounds`` instead of ``VarCATEDualBounds``. (Both have the same API, but the former will yield more powerful results.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a5cb7-e805-4554-adf8-d62a1486ed9c",
   "metadata": {},
   "source": [
    "## Variance of the ITE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed6ebf4-75cd-4f36-8097-0ccc321d4abf",
   "metadata": {},
   "source": [
    "Dual bounds can also be used to upper and lower bound the variance of the individual treatment effect $\\theta = \\text{Var}(Y(1) - Y(0))$, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9372eca-9280-478b-b9c6-f5992cc0b232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc525969ba846549d9d5771d61dddac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba56c0585d2d465f804a4cc55a3c0a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |    Lower |     Upper |\n",
      "|:-----------|---------:|----------:|\n",
      "| Estimate   | 8.37082  | 12.8302   |\n",
      "| SE         | 0.746638 |  0.818289 |\n",
      "| Conf. Int. | 6.90744  | 14.434    |\n"
     ]
    }
   ],
   "source": [
    "vdb = db.varite.VarITEDualBounds(\n",
    "    outcome=data['y'],\n",
    "    treatment=data['W'], \n",
    "    covariates=data['X'],\n",
    "    propensities=data['pis'],\n",
    "    outcome_model='elasticnet',\n",
    ")\n",
    "vdb.fit()\n",
    "print(vdb.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadce15d-3484-46d2-980f-ce9afa381445",
   "metadata": {},
   "source": [
    "## Lee Bounds under monotonicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf0c25-664b-49f1-b61a-5c6654904dee",
   "metadata": {},
   "source": [
    "Lee bounds are a method to bound the average treatment effect in the face of post-treatment nonrandom sample selection, named in honor of  [Lee (2009)](https://www.jstor.org/stable/40247633). Precisely, we assume we observe the following data:\n",
    "\n",
    "- Pre-treatment covariates $X_i \\in \\mathcal{X}$\n",
    "\n",
    "- A binary treatment $W_i \\in \\{0,1\\}$\n",
    " \n",
    "- A post-treatment selection indicator $S_i \\in \\{0,1\\}$.\n",
    " \n",
    "- An outcome $Y_i \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce6a98-26f7-4adf-84a4-bdf7b5c5c254",
   "metadata": {},
   "source": [
    "Note that both $Y_i$ and $S_i$ have potential outcomes $(Y_i(0), Y_i(1))$ and $(S_i(0), S_i(1))$ since both potentially depend on the treatment.\n",
    "\n",
    "A classic example is a setting where $W_i$ denotes enrollment in a job training program, $S_i$ denotes whether a subject entered the labor market, and the outcome $Y_i$ denotes wages. A natural estimand in these settings is the average treatment effect for subjects who would have entered the labor market no matter their treatment status; e.g., "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165992c-a024-4eb7-b255-8442f5046c30",
   "metadata": {},
   "source": [
    "$$E[Y(1) - Y(0) \\mid S(1) = S(0) = 1]. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e5b51-27da-4e55-938b-fcaa76debb94",
   "metadata": {},
   "source": [
    "Dual bounds can be used to bound this partially identified estimand under the **monotonicity** assumption that $S(1) \\ge S(0)$ a.s., as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbcb8ec0-c90c-4ff1-bb32-5a34f10a86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the selection model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88b3b0b089b47a8bc9cd3fd33315b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e76576849047198ad103abd544a2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3853ce12ee40949f580434d84d4fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________Inference_____________________\n",
      "               Lower     Upper\n",
      "Estimate    2.220620  3.155182\n",
      "SE          0.191205  0.193274\n",
      "Conf. Int.  1.845866  3.533992\n",
      "\n",
      "________________Selection model__________________\n",
      "                            Model  No covariates\n",
      "Out-of-sample R^2        0.172740       0.000000\n",
      "Accuracy                 0.703333       0.594444\n",
      "Likelihood (geom. mean)  0.557705       0.508488\n",
      "\n",
      "_________________Outcome model___________________\n",
      "                      Model  No covariates\n",
      "Out-of-sample R^2  0.919644       0.000000\n",
      "RMSE               1.057244       3.729639\n",
      "MAE                0.846142       2.954590\n",
      "\n",
      "________________Treatment model__________________\n",
      "                            Model  No covariates\n",
      "Out-of-sample R^2        0.001111       0.000000\n",
      "Accuracy                 0.500000       0.516667\n",
      "Likelihood (geom. mean)  0.500000       0.499721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create data\n",
    "lee_data = db.gen_data.gen_lee_bound_data(n=900, p=30, sample_seed=123)\n",
    "\n",
    "# fit lee bounds\n",
    "ldb = db.lee.LeeDualBounds(\n",
    "    # data\n",
    "    selections=lee_data['S'], \n",
    "    covariates=lee_data['X'], \n",
    "    treatment=lee_data['W'],\n",
    "    propensities=lee_data['pis'], \n",
    "    outcome=lee_data['y'],\n",
    "    # Model specifications\n",
    "    outcome_model='ridge',\n",
    "    selection_model='monotone_logistic',\n",
    ")\n",
    "ldb.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88378eef-dc0f-47d8-97fb-94b7a67987ed",
   "metadata": {},
   "source": [
    "It is also possible to bound this estimand without the monotonicity assumption using the generic ``DualBounds`` class, although we caution that without the monotonicity assumption, the bounds might be too wide to be useful. Please see [Ji et al. (2023)](https://arxiv.org/pdf/2310.08115.pdf), Section 2.5 for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
