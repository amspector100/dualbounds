{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b271090-0a44-41c9-87b6-868eccf242e8",
   "metadata": {},
   "source": [
    "# The ``DualBounds`` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d883bcd9-def1-4275-9e73-78826287ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys; sys.path.insert(0, \"../../../\")\n",
    "import numpy as np\n",
    "import dualbounds as db\n",
    "from dualbounds.generic import DualBounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff72c31-31b8-4fe6-b30b-081194a30cc1",
   "metadata": {},
   "source": [
    "## General usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139df393-4437-4d89-bbf9-250725a27cf6",
   "metadata": {},
   "source": [
    "The ``DualBounds`` class is the main class in the package, used to bound quantities of the form $E[f(Y(1), Y(0), X)]$. Its usage is as follows. \n",
    "\n",
    "**Step 1**: initialize the ``DualBounds`` class, which takes as an input (i) the data, (ii) the definition of the function $f$ (which defines the estimand $\\theta$), and (iii) a description of the outcome model to use as an input. The user can also input a vector of propensity scores if they are known; else they will be estimated from the data. \n",
    "\n",
    "For example, below, we show how to compute $E[\\mathbb{I}(Y(1) > Y(0)]$, the probability that the treatment effect is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f168fe92-747c-4ed9-b965-2579394c6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data from a linear model\n",
    "data = db.gen_data.gen_regression_data(n=900, p=30, sample_seed=123)\n",
    "\n",
    "# Initialize dual bounds object\n",
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: y0 < y1, # the estimand is E[f(y0, y1, x)]\n",
    "    covariates=data['X'], # n x p covariate matrix\n",
    "    treatment=data['W'], # n-length treatment vector\n",
    "    outcome=data['y'], # n-length outcome vector\n",
    "    propensities=data['pis'], # n-length propensity scores (optional)\n",
    "    outcome_model='ridge', # description of model for Y | X, W\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286a85b-9358-48c5-845a-9caf040b17dd",
   "metadata": {},
   "source": [
    "**Step 2**: after initialization, the ``fit`` method fits the underlying outcome model and produces the final estimates and confidence bounds for the sharp partial identification bounds $\\theta_L \\le \\theta \\le \\theta_U$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a01e35-e141-419e-9370-db8ce1669fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba990171b41b446db127bcf81af7dddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a046eca6c82343f8bfb67f86e13eca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |     Lower |     Upper |\n",
      "|:-----------|----------:|----------:|\n",
      "| Estimate   | 0.6832    | 0.934563  |\n",
      "| SE         | 0.0210876 | 0.0125664 |\n",
      "| Conf. Int. | 0.641869  | 0.959193  |\n"
     ]
    }
   ],
   "source": [
    "# Compute dual bounds and observe output\n",
    "dbnd.fit(\n",
    "    nfolds=5, # number of cross-fitting folds\n",
    "    alpha=0.05, # nominal level,\n",
    "    verbose=True # show progress bars\n",
    ")\n",
    "print(dbnd.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cc518-c07b-4122-8a14-2ed6d0865cff",
   "metadata": {},
   "source": [
    "Note that there are two estimates---a lower and an upper estimate---because $\\theta$ is not identified. One can also produce a more verbose output using the ``summary`` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846b556b-b5a8-40a1-813e-9ea107673c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________Inference_____________________\n",
      "               Lower     Upper\n",
      "Estimate    0.683200  0.934563\n",
      "SE          0.021088  0.012566\n",
      "Conf. Int.  0.641869  0.959193\n",
      "\n",
      "_________________Outcome model___________________\n",
      "                      Model  No covariates\n",
      "Out-of-sample R^2  0.931781       0.000000\n",
      "RMSE               1.055246       4.040167\n",
      "MAE                0.828872       3.228010\n",
      "\n",
      "_________________Treatment model_________________\n",
      "                            Model  No covariates\n",
      "Out-of-sample R^2        0.001111       0.000000\n",
      "Accuracy                 0.500000       0.516667\n",
      "Likelihood (geom. mean)  0.500000       0.499721\n",
      "\n",
      "______________Nonrobust plug-in bounds___________\n",
      "               Lower     Upper\n",
      "Estimate    0.684959  0.923693\n",
      "SE          0.012243  0.007051\n",
      "Conf. Int.  0.660962  0.937513\n",
      "\n",
      "_______________Technical diagnostics_____________\n",
      "                            Lower     Upper\n",
      "Loss from gridsearch     0.015206 -0.000077\n",
      "Max leverage             0.017024  0.017581\n",
      "Worst dual AIPW summand -0.001992  0.002427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbnd.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d29b2d6-111a-4fb6-a1e0-4c76250cc735",
   "metadata": {},
   "source": [
    "Another example below bounds a different estimand, the positive treatment effect $E[\\max(Y(1) - Y(0), 0)]$, using a different underlying ML model (a k-nearest neighbors regressor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d26be6-6262-4334-b675-f10706ce8368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99411506ab4b4250947ff8fa45c24589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633cdec95d2d4ac4a30fe50e4b8eb9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |    Lower |    Upper |\n",
      "|:-----------|---------:|---------:|\n",
      "| Estimate   | 2.92715  | 4.305    |\n",
      "| SE         | 0.175792 | 0.151109 |\n",
      "| Conf. Int. | 2.58261  | 4.60117  |\n"
     ]
    }
   ],
   "source": [
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # new estimand\n",
    "    covariates=data['X'],\n",
    "    treatment=data['W'], \n",
    "    outcome=data['y'], \n",
    "    propensities=data['pis'], \n",
    "    outcome_model='knn', \n",
    ")\n",
    "dbnd.fit()\n",
    "print(dbnd.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47bfceb-da1c-42b7-8603-3906f92377f3",
   "metadata": {},
   "source": [
    "## Choosing the outcome model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4c951-6807-4fce-b384-30c0fb477525",
   "metadata": {},
   "source": [
    "Dual bounds wrap on top of an underlying model which estimates the conditional distributions of $Y(1) \\mid X$ and $Y(0) \\mid X$. There are three ways to specify the underlying model, listed below in order of increasing flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2145bf46-7ed7-4cd2-b64b-760f9121e114",
   "metadata": {},
   "source": [
    "### Method 1: String identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e58aaa-34c0-4039-8760-8122a81036cb",
   "metadata": {},
   "source": [
    "The easiest method is to use one of the string identifiers, such as ``'ridge', 'lasso', 'elasticnet', 'randomforest', 'knn'`` (see the API reference for a complete list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83597e1e-9dc9-41d3-97ac-a93c92bc5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # estimand\n",
    "    covariates=data['X'], \n",
    "    treatment=data['W'], \n",
    "    outcome=data['y'],\n",
    "    # use a random forest to predict E[Y | X]\n",
    "    outcome_model='randomforest',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14482e72-00fa-4a31-9273-3b16185ecf6c",
   "metadata": {},
   "source": [
    "For binary data, these string identifiers assume a nonparametric model where $Y_i \\sim \\text{Bern}(\\mu(X_i, W_i))$ and the conditional mean function $\\mu$ is estimated via one of the models listed above (e.g., a random forest classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39d70e-5290-4be9-916b-50cbede13ba1",
   "metadata": {},
   "source": [
    "For nonbinary data, these string identifiers use a semiparametric regression model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092990ab-ca46-49af-8870-de878e2b2758",
   "metadata": {},
   "source": [
    "$$Y_i = \\mu(X_i, W_i) + \\epsilon_i  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323922f0-cadc-4cc8-ba1f-ccffba1b3294",
   "metadata": {},
   "source": [
    "where the conditional mean function $\\mu(\\cdot, \\cdot)$ is approximated using one of the models listed above (e.g., a random forest or k-nearest neighbors regressor). All methods automatically create interaction terms between the covariates and the treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23c21d-3097-4147-af6b-8b06b175ca33",
   "metadata": {},
   "source": [
    "**Default 1: Homoskedasticity.** By default, these string identifiers estimate a homoskedastic model where the variance of $\\epsilon_i$ does not depend on $X_i$. However, one can also specify a model to use to estimate the heteroskedasticity pattern, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d615561-7d8a-46dd-bab9-d0d8d0f28367",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # estimand\n",
    "    covariates=data['X'], \n",
    "    treatment=data['W'], \n",
    "    outcome=data['y'],\n",
    "    # use a random forest to predict E[Y | X]\n",
    "    outcome_model='randomforest', \n",
    "    # use lasso to predict Var(Y | X)\n",
    "    heterosked_model='lasso',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209752d4-8467-4dcf-85af-c323a9a22fd3",
   "metadata": {},
   "source": [
    "That said, we emphasize that the default (homoskedastic) approach yields valid bounds even under arbitrary heteroskedasticity patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b00e8-7a05-43f0-aef0-87119e8b932c",
   "metadata": {},
   "source": [
    "**Default 2: Nonparametric residual estimates.** By default, these string identifiers estimate the law of $\\epsilon_i$ using the empirical law of the training residuals (or, for ridge estimators, the leave-one-out residuals). However, it is possible to change this by changing the ``eps_dist`` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a77d62b-6049-40b5-8adb-154c069da190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnd = DualBounds(\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # estimand\n",
    "    covariates=data['X'], \n",
    "    treatment=data['W'], \n",
    "    outcome=data['y'],\n",
    "    propensities=data['pis'],\n",
    "    # use a random forest to predict E[Y | X]\n",
    "    outcome_model='randomforest',\n",
    "    # assume a parametric model for the residuals\n",
    "    # (the default is nonparametric)\n",
    "    eps_dist='laplace', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f898a-a6f1-404c-b0de-4820bbda0dd9",
   "metadata": {},
   "source": [
    "### Method 2: A ``dist_reg.DistReg`` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1435d-cf8a-4c11-a12b-bf28f1eae938",
   "metadata": {},
   "source": [
    "Analysts can also specify the outcome model by passing in a model which inherits from ``dualbounds.dist_reg.DistReg``, including the ``CtsDistReg``, ``QuantileDistReg``, or and ``BinaryDistReg`` classes in the ``dualbounds.dist_reg`` submodule. One example is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6c50ae-2806-4df4-8138-b1fd93e4a80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29140ea8eaa4ebaab0b07ddfc239dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd9e868bc884b5a9dda996a353cc7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |   Lower |     Upper |\n",
      "|:-----------|--------:|----------:|\n",
      "| Estimate   | 3.08487 | 3.2955    |\n",
      "| SE         | 0.10184 | 0.0950885 |\n",
      "| Conf. Int. | 2.88527 | 3.48187   |\n"
     ]
    }
   ],
   "source": [
    "Y_model = db.dist_reg.CtsDistReg(\n",
    "    model_type='elasticnet', \n",
    "    eps_dist='empirical',\n",
    "    how_transform='interactions', # create interactions btwn X and W\n",
    "    heterosked_model='lasso',\n",
    "    heterosked_kwargs=dict(cv=3), # kwargs for model for Var(Y|X)\n",
    ")\n",
    "dbnd = DualBounds(\n",
    "    outcome_model=Y_model, # use new model\n",
    "    f=lambda y0, y1, x: np.maximum(y1-y0,0), # estimand\n",
    "    covariates=data['X'], \n",
    "    treatment=data['W'], \n",
    "    outcome=data['y'],\n",
    "    propensities=data['pis'],\n",
    ")\n",
    "dbnd.fit(alpha=0.05)\n",
    "print(dbnd.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da62a40-daad-4d38-a912-f6331dfac790",
   "metadata": {},
   "source": [
    "One can also directly input ``sklearn`` or ``sklearn``-like classes. For example, below we show how to use the ``AdaBoostClassifier`` from sklearn for binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d263885-febd-445a-84d2-b0ab98def55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00eeb643694c4690b354ec9ae0b72254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c5109d873e4fd096f3c883c504e9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |     Lower |     Upper |\n",
      "|:-----------|----------:|----------:|\n",
      "| Estimate   | 0.294189  | 0.397205  |\n",
      "| SE         | 0.0284652 | 0.0226536 |\n",
      "| Conf. Int. | 0.238398  | 0.441606  |\n"
     ]
    }
   ],
   "source": [
    "import sklearn.ensemble as ensemble\n",
    "Y_model = db.dist_reg.BinaryDistReg(\n",
    "    model_type=ensemble.AdaBoostClassifier,\n",
    "    algorithm='SAMME'\n",
    ")\n",
    "dbnd = DualBounds(\n",
    "    outcome_model=Y_model, # use new model\n",
    "    f=lambda y0, y1, x: y0 < y1, # estimand\n",
    "    outcome=data['y'] > 0, # make the outcome binary\n",
    "    # other data\n",
    "    treatment=data['W'], \n",
    "    covariates=data['X'],\n",
    "    propensities=data['pis'],\n",
    ")\n",
    "dbnd.fit(alpha=0.05)\n",
    "print(dbnd.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc525c-8e8a-44e7-89b5-eae4d3da4810",
   "metadata": {},
   "source": [
    "Analysts can also create custom classes inheritting from ``dualbounds.dist_reg.DistReg``, allowing analysts to use (e.g.) custom conditional variance estimators---see the API reference for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a85ff-860c-4fab-9804-a746dd11070e",
   "metadata": {},
   "source": [
    "### Method 3: Input predicted conditional distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a44187-ad1a-48f2-b1a9-78218c5d2eb8",
   "metadata": {},
   "source": [
    "For maximum flexibility, one can also directly input predicted conditional distributions of $Y(1) \\mid X$ and $Y(0) \\mid X$, in the form of a list of batched scipy distributions whose shapes sum to the number of datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf854b53-67f1-4a9a-bb09-33969b4b9196",
   "metadata": {},
   "source": [
    "This is illustrated below, although for simplicity the inputs have nothing to do with the true distributions of $Y(1) \\mid X$ and $Y(0) \\mid X$. Note that in real applications, it is extremely important that the estimates of $Y(1) \\mid X$ and $Y(0) \\mid X$ must be computed using cross-fitting, otherwise the dual bounds may not be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3243ace7-4952-4b31-b4e0-4acd71d1ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974576a790aa4f9dbcdb52176d6fdacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |     Lower |     Upper |\n",
      "|:-----------|----------:|----------:|\n",
      "| Estimate   | 0.318794  | 1.2159    |\n",
      "| SE         | 0.0391768 | 0.0261528 |\n",
      "| Conf. Int. | 0.242008  | 1.26716   |\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "n = len(data['y']) # number of data-points\n",
    "\n",
    "# Initialize object\n",
    "dbnd = DualBounds(\n",
    "    Y_model='lasso', # this will be ignored\n",
    "    f=lambda y0, y1, x : y0 < y1, # estimand\n",
    "    # data\n",
    "    outcome=data['y'],\n",
    "    treatment=data['W'], \n",
    "    covariates=data['X'],\n",
    "    propensities=data['pis'],\n",
    ")\n",
    "\n",
    "# Either of the following input formats work\n",
    "y0_dists = stats.norm(loc=np.zeros(n))\n",
    "y1_dists = [\n",
    "    stats.norm(loc=np.zeros(int(n/2)), scale=2), \n",
    "    stats.norm(loc=np.zeros(int(n/2)), scale=3)\n",
    "]\n",
    "# Compute dual bounds using y0_dists and y1_dists\n",
    "dbnd.fit(\n",
    "    y0_dists=y0_dists,\n",
    "    y1_dists=y1_dists,\n",
    "    suppress_warning=True,\n",
    ")\n",
    "print(dbnd.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3262d-b6c9-42b7-b6c0-13da8b1912b7",
   "metadata": {},
   "source": [
    "This syntax can be useful if in simulations one wants to compute an \"oracle dual bound\" which has perfect knowledge of the conditional distributions of $Y(0) \\mid X$ and $Y(1) \\mid X$, as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae34c28-476e-4d0e-95ef-133b1cc60ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44095a21930142d98e7a0db371c78918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            |     Lower |     Upper |\n",
      "|:-----------|----------:|----------:|\n",
      "| Estimate   | 0.675722  | 0.929035  |\n",
      "| SE         | 0.0208299 | 0.0126281 |\n",
      "| Conf. Int. | 0.634896  | 0.953786  |\n"
     ]
    }
   ],
   "source": [
    "# Compute oracle dual bounds using the true conditional dists of Y0/Y1\n",
    "dbnd.fit(\n",
    "    y0_dists=data['y0_dists'],\n",
    "    y1_dists=data['y1_dists'],\n",
    "    suppress_warning=True,\n",
    ")\n",
    "print(dbnd.results().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370dde1-2801-4f8f-b1a0-c9c3b8720534",
   "metadata": {},
   "source": [
    "Note that the output of the oracle dual bounds is extremely similar to the output of the initial dual bounds in the third cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f763a72-8a66-4cce-ac1f-1939bf9d2e05",
   "metadata": {},
   "source": [
    "## Choosing the propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408b84c-b8fc-4e51-bf0d-3a33cbe21d85",
   "metadata": {},
   "source": [
    "Dual bounds can also apply to observational data where the propensity scores must be estimated. In this case, analysts can specify the model used to estimate the propensity scores---the ``propensity_model``---with one of three methods. First, one can use a string identifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca956b23-4a69-4ff4-95dc-19e34d62012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting propensity scores.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6c88d33bc84acf9f02a02e3dc6cce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865e5e4a018d4f1cbf3ab592dc0d0bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5935ff3e22af4b27aedbceecf193372e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________Inference_____________________\n",
      "               Lower     Upper\n",
      "Estimate    0.692290  0.931634\n",
      "SE          0.020940  0.013118\n",
      "Conf. Int.  0.651249  0.957345\n",
      "\n",
      "_________________Outcome model___________________\n",
      "                      Model  No covariates\n",
      "Out-of-sample R^2  0.931776       0.000000\n",
      "RMSE               1.055278       4.040167\n",
      "MAE                0.827924       3.228010\n",
      "\n",
      "_________________Treatment model_________________\n",
      "                            Model  No covariates\n",
      "Out-of-sample R^2        0.007721       0.000000\n",
      "Accuracy                 0.535556       0.516667\n",
      "Likelihood (geom. mean)  0.501630       0.499721\n",
      "\n",
      "______________Nonrobust plug-in bounds___________\n",
      "               Lower     Upper\n",
      "Estimate    0.687313  0.926805\n",
      "SE          0.012143  0.006866\n",
      "Conf. Int.  0.663513  0.940263\n",
      "\n",
      "_______________Technical diagnostics_____________\n",
      "                            Lower     Upper\n",
      "Loss from gridsearch     0.015727 -0.000082\n",
      "Max leverage             0.017218  0.046430\n",
      "Worst dual AIPW summand -0.001978  0.003025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbnd = DualBounds(\n",
    "    propensity_model='ridge', # logistic ridge for prop. scores\n",
    "    outcome_model='lasso',\n",
    "    f=lambda y0, y1, x: y0 < y1, # estimand\n",
    "    outcome=data['y'],\n",
    "    treatment=data['W'], \n",
    "    covariates=data['X'],\n",
    ")\n",
    "dbnd.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ec004-4f93-4f64-899e-90ca1e08ca42",
   "metadata": {},
   "source": [
    "Second, one can directly input an sklearn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b34e63ca-8785-460a-8ec2-f1b7123298a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting propensity scores.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e1497635854bce8cb220669dc63874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-fitting the outcome model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dc807b42a04563a03ad1524b18d4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating optimal dual variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b336598842e413bbf86a5b0f4b30d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________Inference_____________________\n",
      "               Lower     Upper\n",
      "Estimate    0.685896  0.933438\n",
      "SE          0.021124  0.012638\n",
      "Conf. Int.  0.644494  0.958209\n",
      "\n",
      "_________________Outcome model___________________\n",
      "                      Model  No covariates\n",
      "Out-of-sample R^2  0.931781       0.000000\n",
      "RMSE               1.055246       4.040167\n",
      "MAE                0.828872       3.228010\n",
      "\n",
      "_________________Treatment model_________________\n",
      "                            Model  No covariates\n",
      "Out-of-sample R^2       -0.014126       0.000000\n",
      "Accuracy                 0.501111       0.516667\n",
      "Likelihood (geom. mean)  0.496089       0.499721\n",
      "\n",
      "______________Nonrobust plug-in bounds___________\n",
      "               Lower     Upper\n",
      "Estimate    0.684959  0.923693\n",
      "SE          0.012243  0.007051\n",
      "Conf. Int.  0.660962  0.937513\n",
      "\n",
      "_______________Technical diagnostics_____________\n",
      "                            Lower     Upper\n",
      "Loss from gridsearch     0.015206 -0.000077\n",
      "Max leverage             0.015009  0.024339\n",
      "Worst dual AIPW summand -0.001826  0.002513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dbnd = DualBounds(\n",
    "    propensity_model=ensemble.AdaBoostClassifier(algorithm='SAMME'), \n",
    "    f=lambda y0, y1, x: y0 < y1, # estimand\n",
    "    outcome=data['y'],\n",
    "    treatment=data['W'], \n",
    "    covariates=data['X']\n",
    ")\n",
    "dbnd.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cdbb00-40b2-4f62-9df4-23bcceb70169",
   "metadata": {},
   "source": [
    "Lastly, analysts can also directly estimate the vector propensity scores and input them, although analysts should ensure that they are correctly employing cross-fitting in this case to ensure validity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
